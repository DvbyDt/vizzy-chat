# ðŸ—ï¸ Vizzy Chat - System Architecture

**Version**: 1.0  
**Last Updated**: February 2026  
**Status**: Production Ready

## System Overview

Vizzy Chat is a full-stack AI creative generation platform with intelligent conversation flow and multi-mode content generation. The system is designed for reliability, with built-in fallback mechanisms and graceful degradation.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      USER BROWSER                               â”‚
â”‚                   (React 19 SPA)                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â”‚ HTTPS REST API
                            â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    VERCEL GLOBAL EDGE                           â”‚
â”‚              (Frontend CDN & Static Assets)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â”‚ API Routes
                            â”‚ POST /chat
                            â”‚ POST /reset
                            â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              BACKEND SERVER (Render/HF Spaces)                  â”‚
â”‚                    (FastAPI 0.104.1)                            â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              API Request Handler                         â”‚  â”‚
â”‚  â”‚  â€¢ Request validation (Pydantic models)                 â”‚  â”‚
â”‚  â”‚  â€¢ User session management                              â”‚  â”‚
â”‚  â”‚  â€¢ CORS & security middleware                           â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                            â”‚                                    â”‚
â”‚                            â–¼                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚         Conversation State Manager                       â”‚  â”‚
â”‚  â”‚  â€¢ In-memory conversation_state dict                    â”‚  â”‚
â”‚  â”‚  â€¢ Last interaction tracking                            â”‚  â”‚
â”‚  â”‚  â€¢ Clarifying question detection                        â”‚  â”‚
â”‚  â”‚  â€¢ User mood context (pending_context)                  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                            â”‚                                    â”‚
â”‚                            â–¼                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚         Request Processing Pipeline                      â”‚  â”‚
â”‚  â”‚                                                          â”‚  â”‚
â”‚  â”‚  1. Vague Query Detection                              â”‚  â”‚
â”‚  â”‚     â””â”€ Detect "my day", "today" queries               â”‚  â”‚
â”‚  â”‚                                                          â”‚  â”‚
â”‚  â”‚  2. Clarifying Question Generation                     â”‚  â”‚
â”‚  â”‚     â””â”€ Ask about mood/emotion if needed               â”‚  â”‚
â”‚  â”‚                                                          â”‚  â”‚
â”‚  â”‚  3. Mode-Specific Processing                           â”‚  â”‚
â”‚  â”‚     â”œâ”€ Art: Random style selection                     â”‚  â”‚
â”‚  â”‚     â”œâ”€ Poster: Slogan extraction                       â”‚  â”‚
â”‚  â”‚     â”œâ”€ Story: Story structure generation              â”‚  â”‚
â”‚  â”‚     â”œâ”€ Transform: Style specification                  â”‚  â”‚
â”‚  â”‚     â”œâ”€ Business: Professional aesthetic                â”‚  â”‚
â”‚  â”‚     â””â”€ Personal: User context integration              â”‚  â”‚
â”‚  â”‚                                                          â”‚  â”‚
â”‚  â”‚  4. Prompt Engineering                                  â”‚  â”‚
â”‚  â”‚     â””â”€ Combine user input + mood + style               â”‚  â”‚
â”‚  â”‚                                                          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                            â”‚                                    â”‚
â”‚                            â–¼                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚         Image Generation Engine                         â”‚  â”‚
â”‚  â”‚                                                          â”‚  â”‚
â”‚  â”‚  Primary: Stable Diffusion XL (768x768)               â”‚  â”‚
â”‚  â”‚  â”œâ”€ Provider: Hugging Face API endpoint                â”‚  â”‚
â”‚  â”‚  â”œâ”€ Inference steps: 30                                â”‚  â”‚
â”‚  â”‚  â”œâ”€ Guidance scale: 7.5                                â”‚  â”‚
â”‚  â”‚  â”œâ”€ Retry logic: 3 attempts with 5s backoff            â”‚  â”‚
â”‚  â”‚  â””â”€ Timeout: 120 seconds per request                   â”‚  â”‚
â”‚  â”‚                                                          â”‚  â”‚
â”‚  â”‚  Fallback 1: Custom HF Space                           â”‚  â”‚
â”‚  â”‚  â””â”€ URL: https://Dvbydt-VizzyAPICHAT.hf.space         â”‚  â”‚
â”‚  â”‚                                                          â”‚  â”‚
â”‚  â”‚  Fallback 2: High-quality placeholders                 â”‚  â”‚
â”‚  â”‚  â””â”€ Gradient backgrounds with decorative elements      â”‚  â”‚
â”‚  â”‚                                                          â”‚  â”‚
â”‚  â”‚  Fallback 3: Emergency placeholders                    â”‚  â”‚
â”‚  â”‚  â””â”€ Solid color + prompt text (last resort)            â”‚  â”‚
â”‚  â”‚                                                          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                            â”‚                                    â”‚
â”‚                            â–¼                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚         Image Optimization & Encoding                   â”‚  â”‚
â”‚  â”‚  â€¢ Resize if > 1024px (LANCZOS)                        â”‚  â”‚
â”‚  â”‚  â€¢ PNG compression optimization                         â”‚  â”‚
â”‚  â”‚  â€¢ Base64 encoding for JSON transmission                â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                            â”‚                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                             â–¼
                      JSON Response
                    (base64 images
                 + reasoning + metadata)
```

## Data Flow Diagrams

### Flow 1: Vague Query Resolution

```
User Input: "Draw my day"
    â”‚
    â–¼
Vague Query Detector
â”œâ”€ Detect "my day" / "today" keywords
â”œâ”€ Check if mood/emotion details provided
â””â”€ If vague â†’ STOP, ask clarifying question
    â”‚
    â–¼
Generate Clarifying Question
â”œâ”€ Template: "Could you tell me more about how your day was?"
â”œâ”€ Store original query in conversation_state
â””â”€ Return question to frontend
    â”‚
    â–¼ [User responds with mood]
    â”‚
User Input: "It was dull and I needed motivation"
    â”‚
    â–¼
Extract Mood Keywords
â”œâ”€ Scan for: "dull", "tired", "happy", "energetic", etc.
â”œâ”€ Map to mood description: "dull and unmotivated"
â””â”€ Store mood in pending_context
    â”‚
    â–¼
Enhance Original Query
â”œâ”€ Combine: "Draw my day. The mood is dull and unmotivated."
â”œâ”€ Retrieve mood preference for style
â””â”€ Generate artistic prompt

Result: Context-aware image generation based on clarification
```

### Flow 2: Multi-Scene Story Generation

```
User Input: "Tell a story about an adventure in a magical forest"
    â”‚
    â–¼
Story Mode Detected
â”œâ”€ Message contains keywords suggesting narrative
â””â”€ Route to story generation pipeline
    â”‚
    â–¼
Generate Story Structure (via generate_story module)
â”œâ”€ Use language model to create 3 scenes
â”œâ”€ Extract: scene descriptions, plot progression
â””â”€ Store scenes as list of descriptions
    â”‚
    â–¼
Generate Scene Visuals
â”œâ”€ For each of 3 scenes:
â”‚  â”œâ”€ Create prompt: "scene_text + story_style + mood"
â”‚  â”œâ”€ Call generate_images_hf(prompt, 1)
â”‚  â”œâ”€ Encode result to base64
â”‚  â””â”€ Add to output array
    â”‚
    â–¼
Combine Into Narrative
â”œâ”€ Title: Auto-generated or from story module
â”œâ”€ Scenes array: [desc1 + img1, desc2 + img2, desc3 + img3]
â”œâ”€ Style: Selected from ["cinematic", "illustrated", "children's book"]
â””â”€ Metadata: Generation time, mood, etc.

Result: Sequential visual storytelling with 3 unique images
```

### Flow 3: Poster Mode with Text Overlay

```
User Input: "Create a poster about 'Save the Planet' in green tones"
             (slogan explicitly provided in quotes)
    â”‚
    â–¼
Slogan Extraction
â”œâ”€ Look for: quoted text "...", or "slogan should be"
â”œâ”€ Example: Extract "Save the Planet"
â””â”€ Store for frontend overlay
    â”‚
    â–¼
Generate Poster Background
â”œâ”€ Prompt: "bold typography poster background,
â”‚           Save the Planet, vibrant atmosphere, NO TEXT"
â”œâ”€ Style: Selected from ["minimalist", "bold", "elegant", "modern"]
â””â”€ Explicitly exclude text to avoid conflicts
    â”‚
    â–¼
Encode Images
â”œâ”€ Generate 2 poster variations
â”œâ”€ Optimize for web display
â””â”€ Base64 encode

Result: Background image + slogan text
Frontend: Overlays slogan on top of generated image
```

## Component Architecture

### Backend (FastAPI Application)

```python
main.py                          # FastAPI app initialization
â”œâ”€â”€ generate_images_hf()         # Primary image generation (HF Inference API)
â”œâ”€â”€ generate_with_hf()           # Custom HF Space generation with retries
â”œâ”€â”€ generate_high_quality_placeholders()  # Aesthetic fallback images
â”œâ”€â”€ create_emergency_placeholder()  # Basic fallback (last resort)
â”‚
â”œâ”€â”€ Conversation Management
â”‚   â”œâ”€â”€ get_last_interaction()   # Retrieve previous message/question
â”‚   â”œâ”€â”€ store_question_asked()   # Save clarifying question
â”‚   â”œâ”€â”€ store_generated_response() # Save generation result
â”‚   â””â”€â”€ update_context_with_mood()  # Store mood for session
â”‚
â”œâ”€â”€ Query Analysis
â”‚   â”œâ”€â”€ generate_dynamic_suggestions()  # Mood-based suggestions
â”‚   â”œâ”€â”€ generate_clarifying_question()  # Smart questions
â”‚   â””â”€â”€ extract_slogan()         # Poster text extraction
â”‚
â”œâ”€â”€ Content Generation (async)
â”‚   â”œâ”€â”€ generate_content()       # Main orchestrator
â”‚   â”‚   â”œâ”€ Art Mode
â”‚   â”‚   â”œâ”€ Poster Mode
â”‚   â”‚   â”œâ”€ Story Mode
â”‚   â”‚   â”œâ”€ Transform Mode
â”‚   â”‚   â”œâ”€ Business Mode
â”‚   â”‚   â””â”€ Personal Mode
â”‚   â”‚
â”‚   â””â”€â”€ process_clarified_request()  # Clarification handler
â”‚
â”œâ”€â”€ Utility Functions
â”‚   â”œâ”€â”€ encode_images()          # Base64 encoding with optimization
â”‚   â”œâ”€â”€ generate_dynamic_reasoning()  # Explanation text generation
â”‚   â””â”€â”€ extract_slogan()         # Marketing text extraction
â”‚
â””â”€â”€ API Endpoints
    â”œâ”€â”€ GET / (service info)
    â”œâ”€â”€ GET /health (health check)
    â”œâ”€â”€ POST /chat (main endpoint)
    â”œâ”€â”€ POST /reset (clear context)
    â””â”€â”€ GET /test-deepai (debug)

Supporting Modules:
â”œâ”€â”€ memory.py           # User memory & preferences
â”œâ”€â”€ context.py          # Context tracking
â”œâ”€â”€ story.py            # Story generation
â””â”€â”€ intent.py           # Intent classification (optional)
```

### Frontend (React Application)

```javascript
App.jsx                    # Main component
â”œâ”€â”€ State Management
â”‚   â”œâ”€â”€ messages           // Chat history
â”‚   â”œâ”€â”€ input              // Current user input
â”‚   â”œâ”€â”€ loading            // Generation in progress
â”‚   â”œâ”€â”€ selectedImages     // User selections
â”‚   â”œâ”€â”€ userMode           // Current generation mode
â”‚   â””â”€â”€ expandedReasoning  // UI state
â”‚
â”œâ”€â”€ Component: Chat.js
â”‚   â”œâ”€â”€ Message Display
â”‚   â”‚   â”œâ”€ User messages
â”‚   â”‚   â”œâ”€ Bot text responses
â”‚   â”‚   â”œâ”€ Image grid (max 4 per message)
â”‚   â”‚   â”œâ”€ Story mode display
â”‚   â”‚   â””â”€ Clarifying questions
â”‚   â”‚
â”‚   â”œâ”€â”€ Input Handling
â”‚   â”‚   â”œâ”€ Text input field
â”‚   â”‚   â”œâ”€ Mode selector buttons
â”‚   â”‚   â””â”€ Send button
â”‚   â”‚
â”‚   â””â”€â”€ API Communication
â”‚       â”œâ”€ POST /chat requests
â”‚       â”œâ”€ Response parsing
â”‚       â”œâ”€ Error handling
â”‚       â””â”€ Loading states
â”‚
â””â”€â”€ Styling (App.css)
    â”œâ”€ Color palette (--paper, --accent)
    â”œâ”€ Responsive grid layout
    â”œâ”€ Animation & transitions
    â””â”€ Design system
```

## State Management Architecture

### Frontend State (React)
```javascript
{
  messages: [
    {
      id: 1,
      sender: 'user',
      text: 'Create a peaceful landscape',
      timestamp: 1708536000,
      mode: 'art'
    },
    {
      id: 2,
      sender: 'bot',
      type: 'image',
      content: {
        images: ['base64_1', 'base64_2'],
        reasoning: 'I interpreted...',
        style: 'impressionist'
      },
      timestamp: 1708536018
    }
  ],
  input: '',
  loading: false,
  loadingStage: 'Generating artwork...',
  userMode: 'personal',
  conversationId: 'conv-12345'
}
```

### Backend State (Python)
```python
# In-memory conversation state
conversation_state = {
  'user-123': {
    'last_bot_message': {
      'type': 'question',
      'original_query': 'Draw my day',
      'asked_at': 1708536000
    },
    'mode': 'art',
    'timestamp': 1708536002
  }
}

# Pending context for mood/preferences
pending_context = {
  'user-123': {
    'mood': 'peaceful',
    'original_query': 'Draw my day',
    'question_asked_at': 1708536000
  }
}
```

## Error Handling & Fallbacks

### Three-Tier Fallback System

```
Attempt 1: Primary Generation
â””â”€ Hugging Face API (router.huggingface.co)
   Timeout: 120s
   Retry: 3 attempts with 5s backoff

Attempt 2: If Primary Fails (After 3 retries)
â””â”€ High-quality placeholders
   â””â”€ Gradient backgrounds + decorative elements
   â””â”€ Generated instantly (< 100ms)

Attempt 3: If All Else Fails
â””â”€ Emergency placeholders
   â””â”€ Solid color + prompt text
   â””â”€ Always succeeds, immediate response
```

### Error Handling Flow

```
Request arrives
    â”‚
    â–¼
Try primary generation (3 attempts)
    â”‚
    â”œâ”€ Success â†’ Return images
    â”‚
    â””â”€ Failure â†’ Next tier
        â”‚
        â–¼
    Try high-quality placeholders
        â”‚
        â”œâ”€ Success â†’ Return images
        â”‚
        â””â”€ Failure â†’ Next tier
            â”‚
            â–¼
        Create emergency placeholders
            â”‚
            â””â”€ Always succeeds â†’ Return images

Result: User never sees error, always gets visual response
```

## Retry Strategy

```python
for attempt in range(3):  # Attempt 1, 2, 3
    try:
        # Make request to HF API
        response = requests.post(
            HF_API_URL,
            json={...},
            timeout=120  # 2 minute timeout
        )
        
        if response.status_code == 200:
            # Success - parse and return
            return decode_images(response.content)
        else:
            # HTTP error - continue to retry
            log_warning(f"HTTP {response.status_code}")
            
    except Timeout:
        # Timeout - wait before retry
        await asyncio.sleep(5)
        continue
        
    except Exception:
        # Other error - wait before retry
        await asyncio.sleep(5)
        continue

# After 3 attempts fail - use placeholder
return create_placeholder_images()
```

## API Response Structure

### Success Response (Image Generation)
```json
{
  "type": "image",
  "content": {
    "images": ["base64_image_1", "base64_image_2"],
    "reasoning": "I interpreted your request...",
    "prompt_used": "peaceful landscape, impressionist style...",
    "mode": "art",
    "style": "impressionist",
    "metadata": {
      "generation_time": 18.5,
      "mode": "art",
      "mood": "peaceful"
    }
  }
}
```

### Clarifying Question Response
```json
{
  "type": "question",
  "content": {
    "text": "Could you tell me more about how your day was?"
  }
}
```

### Error Response
```json
{
  "type": "error",
  "content": {
    "text": "Generation failed: [detailed error message]"
  }
}
```

## Deployment Architecture

### Development Environment
```
Local Machine
â”œâ”€â”€ Backend: http://localhost:8000
â”‚   â””â”€ uvicorn main:app --reload
â”œâ”€â”€ Frontend: http://localhost:5173
â”‚   â””â”€ vite dev server
â””â”€â”€ HF Token: .env file
```

### Production Environment
```
Git Repository (GitHub)
    â”‚
    â”œâ”€ Push to main branch
    â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                             â”‚                          â”‚
    â–¼                             â–¼                          â–¼
Vercel                      HF Spaces              OR    Render
(Frontend Deployment)       (Backend Option 1)    (Backend Option 2)
â”œâ”€ Auto-deploy on push      â”œâ”€ Auto-deploy       â”œâ”€ Docker container
â”œâ”€ Global CDN               â”œâ”€ Free T4 GPU       â”œâ”€ Custom runtime
â”œâ”€ Environment vars         â”œâ”€ Model caching     â”œâ”€ Rolling deploy
â””â”€ 99.99% uptime           â””â”€ Hot reload        â””â”€ Easy scaling
```

## Performance Characteristics

| Metric | Value | Notes |
|--------|-------|-------|
| **API Response Time** | 15-30s | Image generation dominant factor |
| **Generation Time** | 15-30s | Varies with HF load |
| **Placeholder Fallback** | <100ms | Instant visual feedback |
| **Image Resolution** | 768Ã—768 | 589,824 pixels per image |
| **Inference Steps** | 30 | Quality/speed tradeoff |
| **Concurrent Requests** | Limited | By backend resource limits |
| **Memory Per Session** | ~1KB | Conversation state only |
| **Database Size** | N/A | No persistent DB (in-memory only) |

## Security Architecture

### CORS Configuration
```python
allow_origins = [
  "http://localhost:5173",           # Local dev
  "http://localhost:5174",           # Alt dev port
  "http://localhost:3000",           # React dev server
  "https://*.vercel.app",            # Vercel previews
  "https://vizzy-chat.vercel.app"    # Production
]
```

### API Key Management
```
Environment Variable: HF_API_TOKEN
â”œâ”€ Loaded from .env file (local)
â”œâ”€ Managed in backend only (never sent to frontend)
â”œâ”€ Validated at startup (fail fast)
â””â”€ Required for every HF API call
```

### Input Validation
```python
# Pydantic models validate all inputs
class ChatRequest(BaseModel):
    user_id: str           # Required
    message: str           # Required
    mode: Optional[str]    # Validated against enum
    conversation_id: Optional[str]  # Optional

# Automatic validation on request
@app.post("/chat")
async def chat(req: ChatRequest):
    # req is guaranteed valid or 422 returned
```

## Scalability Considerations

### Horizontal Scaling
- Multiple backend instances (HF Spaces or Render)
- Load balancer or reverse proxy (nginx/Cloudflare)
- Session state stored in Redis (instead of in-memory)

### Vertical Scaling
- Upgrade GPU (A10, A100 for 3-10x speedup)
- Increase model precision (FP32 â†’ FP16 for memory)
- Cache model in memory for faster inference

### Caching Strategy
- Frontend: Vercel edge caching
- Images: CDN caching with long TTLs
- Models: HF Spaces automatic caching

## Monitoring & Logging

### Frontend Monitoring
- Vercel Analytics (Web Vitals)
- Error tracking (console errors)
- User interactions (optional)

### Backend Monitoring
- HF Spaces logs (stdout/stderr)
- Generation timing metrics
- Error rates and retry statistics
- API token usage tracking

### Health Checks
```python
GET /health
{
  "status": "healthy",
  "hf_configured": true,
  "timestamp": 1708536000.123
}
```

---

**For questions or updates to this document, please open an issue or PR.**

*Document Version: 1.0 | Updated: February 2026*
